\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
\usepackage{neurips_2019}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{thmtools, thm-restate}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}


% \newcommand{\pl}[1]{}
% \newcommand{\tm}[1]{}
% \newcommand{\ak}[1]{}

\newcommand{\pl}[1]{\textcolor{red}{[PL: #1]}}
\newcommand{\tm}[1]{\textcolor{blue}{[TM: #1]}}
\newcommand{\ak}[1]{\textcolor{brown}{[AK: #1]}}

\newcommand{\expect}[0]{\ensuremath{\mathbb{E}}}
\newcommand{\prob}[0]{\ensuremath{\mathbb{P}}}
\newcommand{\ourcal}[0]{the variance-reduced calibrator}
\newcommand{\Ourcal}[0]{The variance-reduced calibrator}

\graphicspath{ {images/} }

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
    %  \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\newcommand{\argmax}{\mathop{\mbox{argmax}}}
\newcommand{\argmin}{\mathop{\mbox{argmin}}}
\newcommand{\argsup}{\mathop{\mbox{argsup}}}
\newcommand{\bins}{\mathcal{B}}

\title{Variance Reduced Uncertainty Calibration}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  David S.~Hippocampus\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}
Applications such as weather forecasting and personalized medicine demand models that output calibrated probability estimates---those representative of the true likelihood of a prediction.
Most models are not calibrated out of the box but are fixed with a recalibration method that post-processes the outputs of the model. \pl{say: Scaling methods fit a parametric model are great, because requires $O(1/\epsilon^2)$ samples, but we find in this work that...}
We find in this work that popular recalibration methods like Platt scaling and temperature scaling are (i) less calibrated than reported and (ii) current techniques cannot estimate how miscalibrated they are.
An alternative method, histogram binning, is sample inefficient -- it requires $O(B/\epsilon^2)$ samples to reach calibration error $\epsilon$ where $B$ is the number of distinct probabilities the model can output.
To solve these problems, we introduce the variance-reduced calibrator, which first fits a parametric function that acts like a baseline for variance reduction and then bins the function values to actually ensure calibration.
This requires only $O(1/\epsilon^2 + B)$ samples.
We also show that the methods used in the machine learning literature to estimate calibration error are suboptimal---we prove that an alternative estimator introduced in the meteorological community requires fewer samples -- samples proportional to $\sqrt{B}$ instead of $B$.
We validate our approach with multi-class calibration experiments on CIFAR-10 and ImageNet, where we get a 35\% lower calibration error than histogram binning and guarantees on true calibration unlike scaling methods.

% Applications such as weather forecasting and personalized medicine demand models that output calibrated probability estimates---those representative of the true likelihood of a prediction.
% Scaling recalibration methods that fit a parametric model are great, because they require $O(1/\epsilon^2)$ samples to achieve calibration error $\epsilon$, but we find in this work that they are (i) less calibrated than reported and (ii) current techniques cannot estimate how miscalibrated they are.
% An alternative method, histogram binning, is sample inefficient -- it requires $O(B/\epsilon^2)$ samples where $B$ is the number of distinct probabilities the model can output.
% To solve these problems, we introduce the variance-reduced calibrator, which first fits a parametric function that acts like a baseline for variance reduction and then bins the function values to actually ensure calibration.
% This requires only $O(1/\epsilon^2 + B)$ samples.\tm{changed the order of two summands}
% We also show that the methods used in the machine learning literature to estimate calibration error are suboptimal -- we prove that an alternative estimator introduced in the meteorological community requires fewer samples -- samples proportional to $\sqrt{B}$ instead of $B$.
% We validate our approach with multi-class calibration experiments on CIFAR-10 and ImageNet, where we get a 2x lower calibration error than histogram binning and guarantees on true calibration unlike scaling methods.
% In this paper, we first show that previous calibration methods like Platt scaling and temperature scaling are (i) less calibrated than reported and (ii) we do not know how miscalibrated they are, because prior work only gives lower bounds for their calibration error \pl{reframe this: previous work (possibly some of our reviewers) did not think they were giving lower bounds; should say instead that methods used by previous work to assess calibration underestimate the true calibration error}.
%   Other methods \pl{what other methods?} like histogram binning are sample inefficient -- they require $O(\frac{B}{\epsilon^2})$ samples to reach calibration error $\epsilon$, where $B$ is the number of model outputs \pl{be clear: which model? this looks like you're talking about number of classes; which is coincidentally what you want, I guess!}. To solve these problems, we introduce the variance-reduced calibrator.
%   The variance-reduced calibrator first fits a parametric function -- which acts like a baseline for variance reduction -- and then bins the function values to actually ensure calibration. This requires only $O(B + \frac{1}{\epsilon^2})$ samples. \pl{we can join some sentences to make it flow better}
%   \pl{compress: We also introduce a new estimator for verifying...}
%   We then turn to the question of how to verify calibration. We introduce a new estimator for the calibration error that requires fewer samples -- samples proportional to $\sqrt{B}$ instead of $B$. We prove finite sample guarantees for all our results, and validate our theory with multi-class calibration experiments on CIFAR-10 and ImageNet, where we get a 2x lower calibration error than histogram binning. \pl{and guarantees on true calibration unlike scaling methods}
\end{abstract}

\pl{Writing tip: find ways to group statements into single sentences so that you get some hierarchical structure:
each sentence should express a set of related ideas, and important ideas are at the beginning of sentences}

\input{intro}

\input{setup}

\input{platt_not_calibrated}

\input{calibrating_models}

\input{verifying_calibration}

\input{related_work}

% \input{experiments}

\bibliographystyle{unsrt}
\bibliography{all}

\appendix

\input{glossary}

\input{appendix_platt_not_calibrated}

\input{appendix_calibrating_models}

\input{appendix_verifying_calibration_proofs}

\end{document}
