\section{Proofs for section~\ref{sec:challenges-measuring}}
\label{sec:appendix-platt-not-calibrated}

% \begin{example}
% For any binning scheme $\mathcal{B}$ and $p \in \mathbb{Z}^+$, there exists a distribution $P$ over $X, Y$ and a function f s.t. $\ell_p\mbox{-CE}(f, B) = 0$ but $\ell_p\mbox{-CE}(f, B) = 0.5$. Note that the $\ell_p\mbox{-CE}$ is always between 0 and 1.
% \end{example}

\continuousNotCalibrated*

\begin{proof}
Converting the intuition into a concrete example is fairly straightforward. Since $f$ is continuous and surjective we can select data distribution $P$ s.t. $f(X)$ is uniformly distributed.
For each interval $I_j = [a, b]$ we set $E[Y | f(X) = s] = 0$ for all $a \leq s \leq \frac{a+b}{2}$ and we set $E[Y | f(X) = s] = 1$ for all $\frac{a+b}{2} \leq x \leq b$.
We can verify that $\ell_p\mbox{-CE}(f, B) = 0$ but $\ell_p\mbox{-CE}(f, B) = 0.5$ for all $p$.
\end{proof}


\binningLowerBound*

\begin{proof}
It suffices to prove the claim for the $\ell_p^p$ error:
\[ (\ell_p\mbox{-CE}(f, \bins{}))^p \leq (\ell_p\mbox{-CE}(f, \bins{}'))^p \leq (\ell_p\mbox{-CE}(f))^p \]
This is because if $p > 0$ then $a \leq b \Leftrightarrow a^p \leq b^p$.

For $p \geq 1$, let $l(a, b) = (|a - b|)^p$.
We note that $l$ is convex in both arguments.
The proof is now a simple result of Jensen's inequality and convexity of $l$.

We begin with the first inequality. Suppose that $\mathcal{B}$ is given by intervals $I_1, ..., I_m$. Let $Z = f(X)$. Note that $Z$ is a random variable.

% We begin with the first inequality.
% Let $Z = f(X)$, and let $J'$ be the bin in $\bins{}'$ $Z$ lands in, that is $Z \in I_{J'}'$.
% Note that $Z$ and $J'$ are random variables.
% The definition of $(\ell_p\mbox{-CE}(f, \bins{}))^p$ is:
% \[ (\ell_p\mbox{-CE}(f, \bins{}))^p = \sum_{j=1}^m P(Z \in I_j) \; l \Big( \mathbb{E}[Z | Z \in I_{J}], \mathbb{E}[Y | Z \in I_{J}] \big] \Big) \]
% Since $\bins{}'$ is finer than $\bins{}$, for every $j$ there exists some $S_j$ s.t. $I_j = \bigcup_{s \in S_j} I_s'$. Also, note that the intervals in a binning scheme are all disjoint. Therefore, we can use the law of total expectation to write $(\ell_p\mbox{-CE}(f, \bins{}))^p$ as:
% \[ (\ell_p\mbox{-CE}(f, \bins{}))^p = \sum_{j=1}^m P(Z \in I_j) \; l \Big( \mathbb{E}_{J' | Z \in I_j} \big[ \mathbb{E}[Z | Z \in I_{J'}'] \big], \mathbb{E}_{J' | Z \in I_j} \big[ \mathbb{E}[Y | Z \in I_{J'}'] \big] \Big) \]
% Where all we did was to expand the inner most expectations.
% Next, the definition of $(\ell_p\mbox{-CE}(f, \bins{}'))^p$ is:
% \[ (\ell_p\mbox{-CE}(f, \bins{}))^p = \sum_{j=1}^n P(Z \in I_j') \; l \Big( \mathbb{E}[Z | Z \in I_{J}'], \mathbb{E}[Y | Z \in I_{J}'] \big] \Big) \]
% By using the law of total expectation, we can write $(\ell_p\mbox{-CE}(f, \bins{}'))^p$ as:
% \[ (\ell_p\mbox{-CE}(f, \bins{}))^p = \sum_{j=1}^m P(Z \in I_j) \; \mathbb{E}_{J' | Z \in I_j} \Big[ l\Big( \mathbb{E}[Z | Z \in I_{J'}'], \mathbb{E}[Y | Z \in I_{J'}'] \Big) \Big] \]


Fix bin $I_j \in \bins{}$.
Since $\bins{}'$ is finer than $\bins{}$, there exists some $S_j$ s.t. $I_j = \bigcup_{s \in S_j} I_s'$.

Define the following notation to simplify the proof.
\[ p_s = P(Z \in I_s' | Z \in I_j) \]
\[ f_s = \mathbb{E}[Z | Z \in I_s']\]
\[ y_s = \mathbb{E}[Y | Z \in I_s']\]
Since $I_j = \bigcup_{s \in S_j} I_s'$ and the intervals are disjoint, we have:
\[ \sum_{s \in S_j} p_s = 1 \]
We can write $(\ell_p\mbox{-CE}(f, \bins{}))^p$ and $(\ell_p\mbox{-CE}(f, \bins{}'))^p$ as a weighted sum of the errors in each bin $I_j$.
\[ (\ell_p\mbox{-CE}(f, \bins{}))^p = \sum_{j=1}^m P(Z \in I_j) \; l\Big( \big( \sum_{s \in S_j} p_s f_s \big), \big( \sum_{s \in S_j} p_s y_s \big) \Big) \]
\[ (\ell_p\mbox{-CE}(f, \bins{}'))^p = \sum_{j=1}^m P(Z \in I_j) \Big( \sum_{s \in S_j} p_s l(f_s, y_s) \Big) \]
Then by Jensen's inequality, from the convexity of $l$,
\[ l\Big( \big( \sum_{s \in S_j} p_s f_s \big), \big( \sum_{s \in S_j} p_s y_s \big) \Big) \leq \sum_{s \in S_j} p_s l(f_s, y_s)  \]
Since this inequality holds for each term in the sum, it holds for the whole sum:
\[ (\ell_p\mbox{-CE}(f, \bins{}))^p \leq (\ell_p\mbox{-CE}(f, \bins{}'))^p \]

The proof of the second inequality, that $(\ell_p\mbox{-CE}(f, \bins{}'))^p \leq (\ell_p\mbox{-CE}(f))^p$, closely parallels the first.

Fix some bin $I_j' \in \bins{}'$. We can write $(\ell_p\mbox{-CE}(f, \bins{}'))^p$ as:
\[ (\ell_p\mbox{-CE}(f, \bins{}'))^p = \sum_{j=1}^n P(Z \in I_j') \; l\Big( \mathbb{E}[Z | Z \in I_j'], \mathbb{E}[Y | Z \in I_j'] \Big) \]
We can write $(\ell_p\mbox{-CE}(f))^p$ as:
\[ (\ell_p\mbox{-CE}(f))^p = \sum_{j=1}^n P(Z \in I_j) \; \mathbb{E}\Big[ l\big( Z, \mathbb{E}[Y | Z] \big) \; | \; Z \in I_j' \Big] \]
By Jensen's inequality,
\[ l\Big( \mathbb{E}[Z | Z \in I_j'], \mathbb{E}[Y | Z \in I_j'] \Big) \leq \mathbb{E}\Big[ l\big( Z, \mathbb{E}[Y | Z] \big) \; | \; Z \in I_j' \Big] \]
Since this inequality holds for each term in the sum, it holds for the whole sum:
\[ (\ell_p\mbox{-CE}(f, \bins{}'))^p \leq (\ell_p\mbox{-CE}(f))^p \]
\end{proof}





\section{Proofs for section~\ref{sec:challenges-measuring}}

































